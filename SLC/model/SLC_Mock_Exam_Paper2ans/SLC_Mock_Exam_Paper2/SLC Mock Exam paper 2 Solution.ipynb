{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Read the dataset (tab, csv, xls, txt, inbuilt dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('mushrooms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2.\tSummarize important observations from the data set (5 Marks)\n",
    "Some pointers which would help you, but don’t be limited by these\n",
    "a.\tFind out number of rows; no. & types of variables (continuous, categorical etc.)\n",
    "b.\tCalculate five-point summary for numerical variables\n",
    "c.\tSummarize observations for categorical variables – no. of categories, % observations in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 23)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## a)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "  \n",
    "# label_encoder object knows how to understand word labels. \n",
    "le = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "df= df.apply(LabelEncoder().fit_transform) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      "class                       8124 non-null int32\n",
      "cap-shape                   8124 non-null int32\n",
      "cap-surface                 8124 non-null int32\n",
      "cap-color                   8124 non-null int32\n",
      "bruises                     8124 non-null int32\n",
      "odor                        8124 non-null int32\n",
      "gill-attachment             8124 non-null int32\n",
      "gill-spacing                8124 non-null int32\n",
      "gill-size                   8124 non-null int32\n",
      "gill-color                  8124 non-null int32\n",
      "stalk-shape                 8124 non-null int32\n",
      "stalk-root                  8124 non-null int32\n",
      "stalk-surface-above-ring    8124 non-null int32\n",
      "stalk-surface-below-ring    8124 non-null int32\n",
      "stalk-color-above-ring      8124 non-null int32\n",
      "stalk-color-below-ring      8124 non-null int32\n",
      "veil-type                   8124 non-null int32\n",
      "veil-color                  8124 non-null int32\n",
      "ring-number                 8124 non-null int32\n",
      "ring-type                   8124 non-null int32\n",
      "spore-print-color           8124 non-null int32\n",
      "population                  8124 non-null int32\n",
      "habitat                     8124 non-null int32\n",
      "dtypes: int32(23)\n",
      "memory usage: 730.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## b) no need of describe as all are categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      "class                       8124 non-null int32\n",
      "cap-shape                   8124 non-null int32\n",
      "cap-surface                 8124 non-null int32\n",
      "cap-color                   8124 non-null int32\n",
      "bruises                     8124 non-null int32\n",
      "odor                        8124 non-null int32\n",
      "gill-attachment             8124 non-null int32\n",
      "gill-spacing                8124 non-null int32\n",
      "gill-size                   8124 non-null int32\n",
      "gill-color                  8124 non-null int32\n",
      "stalk-shape                 8124 non-null int32\n",
      "stalk-root                  8124 non-null int32\n",
      "stalk-surface-above-ring    8124 non-null int32\n",
      "stalk-surface-below-ring    8124 non-null int32\n",
      "stalk-color-above-ring      8124 non-null int32\n",
      "stalk-color-below-ring      8124 non-null int32\n",
      "veil-type                   8124 non-null int32\n",
      "veil-color                  8124 non-null int32\n",
      "ring-number                 8124 non-null int32\n",
      "ring-type                   8124 non-null int32\n",
      "spore-print-color           8124 non-null int32\n",
      "population                  8124 non-null int32\n",
      "habitat                     8124 non-null int32\n",
      "dtypes: int32(23)\n",
      "memory usage: 730.0 KB\n"
     ]
    }
   ],
   "source": [
    "# c) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3.\tCheck for defects in the data. Perform necessary actions to ‘fix’ these defects (5 Marks)\n",
    "Some pointers which would help you, but don’t be limited by these\n",
    "a.\tDo variables have missing/null values?\n",
    "b.\tDo variables have outliers?\n",
    "c.\tIs the Target distributed evenly? Is it a defect? If Yes, what steps are being taken to rectify the problem. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                       0\n",
       "cap-shape                   0\n",
       "cap-surface                 0\n",
       "cap-color                   0\n",
       "bruises                     0\n",
       "odor                        0\n",
       "gill-attachment             0\n",
       "gill-spacing                0\n",
       "gill-size                   0\n",
       "gill-color                  0\n",
       "stalk-shape                 0\n",
       "stalk-root                  0\n",
       "stalk-surface-above-ring    0\n",
       "stalk-surface-below-ring    0\n",
       "stalk-color-above-ring      0\n",
       "stalk-color-below-ring      0\n",
       "veil-type                   0\n",
       "veil-color                  0\n",
       "ring-number                 0\n",
       "ring-type                   0\n",
       "spore-print-color           0\n",
       "population                  0\n",
       "habitat                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b1cc1adac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) \n",
    "pd.crosstab(index = df['bruises'],columns=df['class']).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b1cc4edc18>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(index = df['cap-surface'],columns=df['class']).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in this way students need to plot and decide whether outliers are there or not.\n",
    "## mostly there aren't any outlier but if student gives proper justification then weightage has to be given to the student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4208\n",
       "1    3916\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c)\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## no the class has come baisness towards the class 0. further we will be imposing over sampling technique as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4.\tSummarize relationships among variables (10 marks)               \n",
    "a.\tPlot relevant categorical plots. Find out which are the variables most correlated or appear to be in causation with Target? Do you want to exclude some variables from the model based on this analysis? What other actions will you take?\n",
    "b.\tPlot all independent variables with the target & find out the relationship? Perform the Relevant Tests to find out if the Independent variables are associated with the Target Variable.\n",
    "\n",
    " Hint: based on your observations you may want to transform features or create additional features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
       "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
       "       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
       "       'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
       "       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
       "       'ring-type', 'spore-print-color', 'population', 'habitat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b1cc69d668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## b)\n",
    "pd.crosstab(index = df['cap-surface'],columns=df['class']).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## none of them are highly correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: only two columns have to be dropped because of same value throughout the rows.\n",
    "## They are veil-type, veil-color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5.\tSplit dataset into train and test (70:30) (5 marks)\n",
    "a.\tAre both train and test representative of the overall data? How would you ascertain this statistically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class','veil-color'], axis = 1)\n",
    "y = df['class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5686, 21)\n",
      "(8124, 21)\n",
      "(5686,)\n",
      "(8124,)\n",
      "(2438, 21)\n",
      "(2438,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X.shape)\n",
    "print(y_train.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's take the chisquare test\n",
    "## H0 = the train and population samples are not dependent.\n",
    "## Ha = the train and population samples are dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2951</td>\n",
       "      <td>0</td>\n",
       "      <td>2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2735</td>\n",
       "      <td>2735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2951</td>\n",
       "      <td>2735</td>\n",
       "      <td>5686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class     0     1   All\n",
       "class                  \n",
       "0      2951     0  2951\n",
       "1         0  2735  2735\n",
       "All    2951  2735  5686"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont = pd.crosstab(\n",
    "    y,\n",
    "    y_train,\n",
    "    margins = True\n",
    ")\n",
    "cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5686.000000000001, 0.0, 4, array([[1531.5513542, 1419.4486458, 2951.       ],\n",
       "        [1419.4486458, 1315.5513542, 2735.       ],\n",
       "        [2951.       , 2735.       , 5686.       ]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "scipy.stats.chi2_contingency(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chi2 value = 5686, p = 0, dof= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If p-value <= alpha(0.05): significant result, reject null hypothesis (H0), dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2438.0, 0.0, 4, array([[ 648.09228876,  608.90771124, 1257.        ],\n",
       "        [ 608.90771124,  572.09228876, 1181.        ],\n",
       "        [1257.        , 1181.        , 2438.        ]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont = pd.crosstab(\n",
    "    y,\n",
    "    y_test,\n",
    "    margins = True\n",
    ")\n",
    "import scipy.stats\n",
    "scipy.stats.chi2_contingency(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If p-value <= alpha(0.05): significant result, reject null hypothesis (H0), dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6.\tFit a base model and explain the reason of selecting that model. Please write your key observations (15 marks) \n",
    "a.\tWhat is the overall Accuracy? Please comment on whether it is good or not. \n",
    "b.\tWhat is Precision, Recall and F1 Score and what will be the optimization objective keeping in mind the problem statement.\n",
    "c.\tWhich variables are significant?\n",
    "d.\tWhat is Cohen’s Kappa Value and what inference do you make from the model\n",
    "e.\tWhich other key model output parameters do you want to look at? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lavanya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  cap-surface  cap-shape  cap-color  bruises  odor  gill-attachment  \\\n",
       "0    1.0            2          5          4        1     6                1   \n",
       "1    1.0            2          5          9        1     0                1   \n",
       "2    1.0            2          0          8        1     3                1   \n",
       "3    1.0            3          5          8        1     6                1   \n",
       "4    1.0            2          5          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  ...  stalk-root  \\\n",
       "0             0          1           4  ...           3   \n",
       "1             0          0           4  ...           2   \n",
       "2             0          0           5  ...           2   \n",
       "3             0          1           5  ...           3   \n",
       "4             1          0           4  ...           3   \n",
       "\n",
       "   stalk-surface-above-ring  stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "0                         2                         2                       7   \n",
       "1                         2                         2                       7   \n",
       "2                         2                         2                       7   \n",
       "3                         2                         2                       7   \n",
       "4                         2                         2                       7   \n",
       "\n",
       "   stalk-color-below-ring  ring-number  ring-type  spore-print-color  \\\n",
       "0                       7            1          4                  2   \n",
       "1                       7            1          4                  3   \n",
       "2                       7            1          4                  3   \n",
       "3                       7            1          4                  2   \n",
       "4                       7            1          0                  3   \n",
       "\n",
       "   population  habitat  \n",
       "0           3        5  \n",
       "1           2        1  \n",
       "2           2        3  \n",
       "3           3        5  \n",
       "4           0        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['cap-surface','cap-shape','cap-color','bruises','odor','gill-attachment','gill-spacing','gill-size','gill-color',\n",
    "        'stalk-shape', 'stalk-root', 'stalk-surface-above-ring','stalk-surface-below-ring', 'stalk-color-above-ring',\n",
    "       'stalk-color-below-ring',  'ring-number',\n",
    "       'ring-type', 'spore-print-color', 'population', 'habitat']]\n",
    "y = df['class']\n",
    "\n",
    "from statsmodels.tools import add_constant as add_constant\n",
    "df_constant = add_constant(X)\n",
    "df_constant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
       "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
       "       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
       "       'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
       "       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
       "       'ring-type', 'spore-print-color', 'population', 'habitat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3148\n",
       "1    2148\n",
       "4    1144\n",
       "2     832\n",
       "5     368\n",
       "3     292\n",
       "6     192\n",
       "Name: habitat, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['habitat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reducing the number of features to make it more categorical friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking 5 as others  for cap-color\n",
    "df.loc[df['cap-color']==6,'cap-color'] = 5\n",
    "df.loc[df['cap-color']==7,'cap-color'] = 5\n",
    "df.loc[df['cap-color']==8,'cap-color'] = 5\n",
    "df.loc[df['cap-color']==9,'cap-color'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking 5 and above as others  for odor\n",
    "df.loc[df['odor']==6,'odor'] = 6\n",
    "df.loc[df['odor']==7,'odor'] = 6\n",
    "df.loc[df['odor']==8,'odor'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking 6 and above as others  for gill-color\n",
    "df.loc[df['gill-color']==6,'gill-color'] = 6\n",
    "df.loc[df['gill-color']==7,'gill-color'] = 6\n",
    "df.loc[df['gill-color']==8,'gill-color'] = 6\n",
    "df.loc[df['gill-color']==9,'gill-color'] = 6\n",
    "df.loc[df['gill-color']==10,'gill-color'] = 6\n",
    "df.loc[df['gill-color']==11,'gill-color'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking 5 and above as others  for stalk-color-below-ring\n",
    "df.loc[df['stalk-color-below-ring']==6,'stalk-color-below-ring'] = 5\n",
    "df.loc[df['stalk-color-below-ring']==7,'stalk-color-below-ring'] = 5\n",
    "df.loc[df['stalk-color-below-ring']==8,'stalk-color-below-ring'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking 5 and above as others  for spore-print-color\n",
    "df.loc[df['spore-print-color']==6,'spore-print-color'] = 5\n",
    "df.loc[df['spore-print-color']==7,'spore-print-color'] = 5\n",
    "df.loc[df['spore-print-color']==8,'spore-print-color'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## taking 5 and above as others  for habitat\n",
    "df.loc[df['habitat']==6,'habitat'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.175056\n",
      "         Iterations 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>class</td>      <th>  No. Observations:  </th>  <td>  8124</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  8103</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    20</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Tue, 19 Nov 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.7472</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:05:21</td>     <th>  Log-Likelihood:    </th> <td> -1422.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -5625.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                    <td>   10.4947</td> <td>    0.697</td> <td>   15.046</td> <td> 0.000</td> <td>    9.128</td> <td>   11.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cap-surface</th>              <td>    0.5056</td> <td>    0.058</td> <td>    8.719</td> <td> 0.000</td> <td>    0.392</td> <td>    0.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cap-shape</th>                <td>   -0.0069</td> <td>    0.030</td> <td>   -0.228</td> <td> 0.820</td> <td>   -0.066</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cap-color</th>                <td>   -0.0935</td> <td>    0.024</td> <td>   -3.948</td> <td> 0.000</td> <td>   -0.140</td> <td>   -0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bruises</th>                  <td>   -0.4107</td> <td>    0.290</td> <td>   -1.418</td> <td> 0.156</td> <td>   -0.978</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>odor</th>                     <td>   -0.8803</td> <td>    0.056</td> <td>  -15.743</td> <td> 0.000</td> <td>   -0.990</td> <td>   -0.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gill-attachment</th>          <td>    2.7519</td> <td>    0.511</td> <td>    5.389</td> <td> 0.000</td> <td>    1.751</td> <td>    3.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gill-spacing</th>             <td>  -10.4165</td> <td>    0.618</td> <td>  -16.860</td> <td> 0.000</td> <td>  -11.627</td> <td>   -9.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gill-size</th>                <td>   10.5288</td> <td>    0.509</td> <td>   20.690</td> <td> 0.000</td> <td>    9.531</td> <td>   11.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gill-color</th>               <td>   -0.1160</td> <td>    0.020</td> <td>   -5.877</td> <td> 0.000</td> <td>   -0.155</td> <td>   -0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stalk-shape</th>              <td>    1.0580</td> <td>    0.330</td> <td>    3.203</td> <td> 0.001</td> <td>    0.411</td> <td>    1.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stalk-root</th>               <td>   -2.3529</td> <td>    0.277</td> <td>   -8.497</td> <td> 0.000</td> <td>   -2.896</td> <td>   -1.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stalk-surface-above-ring</th> <td>   -7.2307</td> <td>    0.386</td> <td>  -18.738</td> <td> 0.000</td> <td>   -7.987</td> <td>   -6.474</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stalk-surface-below-ring</th> <td>    0.1205</td> <td>    0.135</td> <td>    0.895</td> <td> 0.371</td> <td>   -0.143</td> <td>    0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stalk-color-above-ring</th>   <td>   -0.1818</td> <td>    0.038</td> <td>   -4.750</td> <td> 0.000</td> <td>   -0.257</td> <td>   -0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stalk-color-below-ring</th>   <td>   -0.0654</td> <td>    0.037</td> <td>   -1.748</td> <td> 0.080</td> <td>   -0.139</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ring-number</th>              <td>    2.5820</td> <td>    0.430</td> <td>    6.007</td> <td> 0.000</td> <td>    1.740</td> <td>    3.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ring-type</th>                <td>    1.4956</td> <td>    0.147</td> <td>   10.163</td> <td> 0.000</td> <td>    1.207</td> <td>    1.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spore-print-color</th>        <td>   -0.0852</td> <td>    0.046</td> <td>   -1.865</td> <td> 0.062</td> <td>   -0.175</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>population</th>               <td>   -0.6359</td> <td>    0.081</td> <td>   -7.857</td> <td> 0.000</td> <td>   -0.794</td> <td>   -0.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>habitat</th>                  <td>    0.0228</td> <td>    0.036</td> <td>    0.627</td> <td> 0.531</td> <td>   -0.048</td> <td>    0.094</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.21 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  class   No. Observations:                 8124\n",
       "Model:                          Logit   Df Residuals:                     8103\n",
       "Method:                           MLE   Df Model:                           20\n",
       "Date:                Tue, 19 Nov 2019   Pseudo R-squ.:                  0.7472\n",
       "Time:                        15:05:21   Log-Likelihood:                -1422.2\n",
       "converged:                       True   LL-Null:                       -5625.9\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "const                       10.4947      0.697     15.046      0.000       9.128      11.862\n",
       "cap-surface                  0.5056      0.058      8.719      0.000       0.392       0.619\n",
       "cap-shape                   -0.0069      0.030     -0.228      0.820      -0.066       0.052\n",
       "cap-color                   -0.0935      0.024     -3.948      0.000      -0.140      -0.047\n",
       "bruises                     -0.4107      0.290     -1.418      0.156      -0.978       0.157\n",
       "odor                        -0.8803      0.056    -15.743      0.000      -0.990      -0.771\n",
       "gill-attachment              2.7519      0.511      5.389      0.000       1.751       3.753\n",
       "gill-spacing               -10.4165      0.618    -16.860      0.000     -11.627      -9.206\n",
       "gill-size                   10.5288      0.509     20.690      0.000       9.531      11.526\n",
       "gill-color                  -0.1160      0.020     -5.877      0.000      -0.155      -0.077\n",
       "stalk-shape                  1.0580      0.330      3.203      0.001       0.411       1.705\n",
       "stalk-root                  -2.3529      0.277     -8.497      0.000      -2.896      -1.810\n",
       "stalk-surface-above-ring    -7.2307      0.386    -18.738      0.000      -7.987      -6.474\n",
       "stalk-surface-below-ring     0.1205      0.135      0.895      0.371      -0.143       0.385\n",
       "stalk-color-above-ring      -0.1818      0.038     -4.750      0.000      -0.257      -0.107\n",
       "stalk-color-below-ring      -0.0654      0.037     -1.748      0.080      -0.139       0.008\n",
       "ring-number                  2.5820      0.430      6.007      0.000       1.740       3.424\n",
       "ring-type                    1.4956      0.147     10.163      0.000       1.207       1.784\n",
       "spore-print-color           -0.0852      0.046     -1.865      0.062      -0.175       0.004\n",
       "population                  -0.6359      0.081     -7.857      0.000      -0.794      -0.477\n",
       "habitat                      0.0228      0.036      0.627      0.531      -0.048       0.094\n",
       "============================================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.21 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Base Model\n",
    "\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "\n",
    "st.chisqprob = lambda chisq, df: st.chi2.sf(chisq, X)\n",
    "cols=df_constant.columns\n",
    "model=sm.Logit(y,df_constant[cols])\n",
    "result=model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9426661976785086\n",
      "test accuracy: 0.94298605414274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lavanya\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('train accuracy:', model.score(X_train, y_train))\n",
    "print('test accuracy:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      1257\n",
      "           1       0.95      0.93      0.94      1181\n",
      "\n",
      "    accuracy                           0.94      2438\n",
      "   macro avg       0.94      0.94      0.94      2438\n",
      "weighted avg       0.94      0.94      0.94      2438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7.\tHow do you improve the accuracy of the model? Write clearly the changes that you will make before re-fitting the model. Fit the final model. (20 marks)\n",
    "Please feel free to have any number of iterations to get to the final answer. Marks are awarded based on the quality of final model you are able to achieve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Students can go for smote.\n",
    "## students can go for various models and ensemble techniques.\n",
    "## Codes has been supplied down.\n",
    "## Feature selection technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum number of features: 7\n",
      "Score with 7 features: 0.948728\n"
     ]
    }
   ],
   "source": [
    "## feature selection\n",
    "## applying RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "import numpy as np\n",
    "model = LogisticRegression()\n",
    "#no of features\n",
    "nof_list=np.arange(1,22)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "    model = LogisticRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'stalk-root',\n",
      "       'stalk-surface-above-ring', 'ring-number'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Let's find the 7 important features\n",
    "\n",
    "cols = list(X.columns)\n",
    "model = LogisticRegression()\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, 7)             \n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y)              \n",
    "temp = pd.Series(rfe.support_,index = cols)\n",
    "selected_features_rfe = temp[temp==True].index\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 23)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earlier by using 23 featueres we were getting approx 94 %\n",
    "## And after doing rfe, just by using 7 features I am able to get more than 90% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['bruises','gill-attachment','gill-spacing','gill-size', 'stalk-shape','ring-number','ring-type']]\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train : 0.9199788955328878\n",
      "accuracy test : 0.9200164068908941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy train :', model.score(X_train, y_train))\n",
    "print('accuracy test :', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train : 0.9482940555750967\n",
      "accuracy test : 0.9466776045939295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='gini')\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy train :', model.score(X_train, y_train))\n",
    "print('accuracy test :', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train : 0.9482940555750967\n",
      "accuracy test : 0.9466776045939295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy train :', model.score(X_train, y_train))\n",
    "print('accuracy test :', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train : 0.9482940555750967\n",
      "accuracy test : 0.9466776045939295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy train :', model.score(X_train, y_train))\n",
    "print('accuracy test :', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train : 0.9194512838550827\n",
      "accuracy test : 0.9204265791632485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy train :', model.score(X_train, y_train))\n",
    "print('accuracy test :', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ensemble Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train : 0.9482940555750967\n",
      "accuracy test : 0.9466776045939295\n"
     ]
    }
   ],
   "source": [
    "## Ensemble Techniques\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy train :', model.score(X_train, y_train))\n",
    "print('accuracy test :', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bagging\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "clf1 = DecisionTreeClassifier(criterion='entropy')\n",
    "clf2 = KNeighborsClassifier(n_neighbors=5)    \n",
    "clf3 = DecisionTreeClassifier(criterion='gini')\n",
    "clf4 = LogisticRegression()\n",
    "clf5 = GaussianNB()\n",
    "\n",
    "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
    "bagging2 = BaggingClassifier(base_estimator=clf2, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
    "bagging3 = BaggingClassifier(base_estimator=clf3, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
    "bagging4 = BaggingClassifier(base_estimator=clf4, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
    "bagging5 = BaggingClassifier(base_estimator=clf5, n_estimators=10, max_samples=0.8, max_features=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87 (+/- 0.07) [Dt_entorpy]\n",
      "Accuracy: 0.84 (+/- 0.05) [K-NN]\n",
      "Accuracy: 0.90 (+/- 0.04) [Dt_gini]\n",
      "Accuracy: 0.83 (+/- 0.10) [LogisticRegression]\n"
     ]
    }
   ],
   "source": [
    "label = ['Dt_entorpy', 'K-NN', 'Dt_gini', 'LogisticRegression','GaussianNB', 'Bagging Tree entopy', 'Bagging K-NN',\n",
    "        'Bagging Tree gini', 'Bagging LR' , 'Bagging GaussianNB']\n",
    "clf_list = [clf1, clf2,clf3 , clf4, clf5, bagging1, bagging2 , bagging3 , bagging4 , bagging5]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "for clf, label, grd in zip(clf_list, label, grid):        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print( \"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boosting\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "clf1 = DecisionTreeClassifier(criterion='entropy')\n",
    "clf2 = KNeighborsClassifier(n_neighbors=3)    \n",
    "clf3 = DecisionTreeClassifier(criterion='gini')\n",
    "clf4 = LogisticRegression()\n",
    "clf5 = GaussianNB()\n",
    "clf6 = RandomForestClassifier()\n",
    "\n",
    "boosting1 = AdaBoostClassifier(base_estimator=clf1, n_estimators=10)\n",
    "boosting2 = AdaBoostClassifier(base_estimator=clf2, n_estimators=10, random_state=1)\n",
    "boosting3 = AdaBoostClassifier(base_estimator=clf3, n_estimators=10)\n",
    "boosting4 = AdaBoostClassifier(base_estimator=clf4, n_estimators=10)\n",
    "boosting5 = AdaBoostClassifier(base_estimator=clf5, n_estimators=10)\n",
    "boosting6 = AdaBoostClassifier(base_estimator=clf6, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87 (+/- 0.07) [Dt_entorpy]\n",
      "Accuracy: 0.84 (+/- 0.05) [K-NN]\n",
      "Accuracy: 0.87 (+/- 0.07) [Dt_gini]\n",
      "Accuracy: 0.83 (+/- 0.10) [LogisticRegression]\n",
      "Accuracy: 0.70 (+/- 0.27) [GaussianNB]\n",
      "Accuracy: 0.84 (+/- 0.05) [RF]\n"
     ]
    }
   ],
   "source": [
    "label = ['Dt_entorpy', 'K-NN', 'Dt_gini', 'LogisticRegression','GaussianNB','RF']\n",
    "clf_list = [clf1, clf2,clf3 , clf4, clf5,clf6]\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "grid = itertools.product([0,5],repeat=3)\n",
    "\n",
    "for clf, label, grd in zip(clf_list, label, grid):        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print( \"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87 (+/- 0.08) [boosting Tree entopy]\n",
      "Accuracy: 0.84 (+/- 0.11) [boosting Tree gini]\n",
      "Accuracy: 0.62 (+/- 0.20) [boosting LR]\n",
      "Accuracy: 0.62 (+/- 0.10) [boosting GaussianNB]\n",
      "Accuracy: 0.84 (+/- 0.11) [boosting RF]\n"
     ]
    }
   ],
   "source": [
    "label = ['boosting Tree entopy','boosting Tree gini', 'boosting LR' , 'boosting GaussianNB' , 'boosting RF']\n",
    "clf_list = [boosting1 ,boosting3 , boosting4 , boosting5 , boosting6]\n",
    "grid = itertools.product([0,5],repeat=3)\n",
    "\n",
    "for clf, label, grd in zip(clf_list, label, grid):        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print( \"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "        \n",
    "    clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Among all the models we found out that random forest works the best as it gives the best accuracy and is neither an overfit \n",
    "## nor an underfit model.\n",
    "\n",
    "## This random forest gives the same accuracy as our base model but just by using 7 features.\n",
    "## This reduces the burdan on my model. As for base model we used 23 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8.\tSummarize as follows (10 marks) \n",
    "1.\tSummarize the overall fit of the model and list down the measures to prove that it is a good model\n",
    "2.\tWrite down a business interpretation/explanation of the model – which variables are affecting the target the most and explain the relationship. Feel free to use charts or graphs to explain.\n",
    "3.\tWhat changes from the base model had the most effect on model performance?\n",
    "4.\tWhat are the key risks to your results and interpretation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train : 0.9482940555750967\n",
      "accuracy test : 0.9466776045939295\n"
     ]
    }
   ],
   "source": [
    "#1. FInal model with 7 features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print('accuracy train :', model.score(X_train, y_train))\n",
    "print('accuracy test :', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neither overfit nor underfit. Best fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\n",
    "## Imp features :: 'bruises','gill-attachment','gill-spacing','gill-size', 'stalk-shape','ring-number','ring-type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\n",
    "## Majorly the feature importance technique i.e. RFE helped us to reach this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. For this question, if the student is able to write some points with relevant proofs then it should be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
